# if more than 100 config lines about to go here, use tasks.ini instead

spark.executor.memory=! (node memory - 2g - overhead 10%) / executors per node
spark.executor.instances=! node count * executors per node
spark.cores.max=! node cores * node count
spark.executor.cores=! node cores / executors per node

spark.network.timeout=10000s
spark.speculation=false
spark.master=yarn
spark.submit.deployMode=cluster
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2

spark.driver.cores=dummy
spark.driver.memory=dummy
spark.driver.maxResultSize=100g

maximizeResourceAllocation={true|false} if true, all resources on nodes will be utilized by executors, but one node will run exclusively a driver, with no regular executors at all

spark.executor.extraJavaOptions=-XX:+UseParallelGC -XX:+UseParallelOldGC
